{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(os.path.join(current_dir, \"Audio_Files\\\\UK_OST\\\\03SandsOfTide.mp3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "beat_times = librosa.frames_to_time(beat_frames, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_harmonic, y_percussive = librosa.effects.hpss(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC is p much the intensity of the different audio bands\n",
    "# This is huge bc it's a lot of frames\n",
    "hop_length = 512\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "mfcc_delta = librosa.feature.delta(mfcc)\n",
    "# Represents the changein MFCC per \n",
    "beat_mfcc_delta = librosa.util.sync(np.vstack([mfcc, mfcc_delta]), beat_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is cool, it's the like relative strength of pitches\n",
    "chromagram = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "beat_chroma = librosa.util.sync(chromagram, beat_frames, aggregate=np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_features = np.vstack([beat_chroma, beat_mfcc_delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This flattens the matrix into a vector we can pass into our model\n",
    "# Do it by beats tbh, frames is a LOT. At least for now.\n",
    "# The first 12 features are the chromagram - the intensity of sound in semitones from C to Bb\n",
    "beat_features_flattened = beat_features.T.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
